{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_openai import AzureOpenAI, AzureOpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Récupérer les clés API d'Azure\n",
    "azure_openai_api_key = os.getenv('AZURE_OPENAI_API_KEY_4')\n",
    "azure_openai_api_endpoint = os.getenv('AZURE_OPENAI_API_ENDPOINT_4')\n",
    "deployment_name = os.getenv(\"AZURE_DEPLOYMENT_NAME_4\")\n",
    "\n",
    "# Modèle d'embeddings\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    openai_api_key=azure_openai_api_key,\n",
    "    azure_deployment='text-embedding-3-large',\n",
    "    azure_endpoint=azure_openai_api_endpoint,\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    chunk_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de l'embedding : 3072\n"
     ]
    }
   ],
   "source": [
    "# Création d'un document simple pour tester\n",
    "doc_test = Document(page_content=\"Ce texte est un exemple pour tester la dimension des embeddings.\")\n",
    "\n",
    "# Calcul des embeddings pour ce document\n",
    "embedding = embedding_model.embed_query(doc_test.page_content)\n",
    "\n",
    "# Affichage de la dimension des embeddings\n",
    "print(f\"Dimensions de l'embedding : {len(embedding)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AzureChatOpenAI(api_key=azure_openai_api_key,\n",
    "                        api_version=\"2023-12-01-preview\",\n",
    "                        azure_endpoint=azure_openai_api_endpoint,\n",
    "                        model=deployment_name,\n",
    "                        temperature=0\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Le cheval le plus célèbre de Napoléon était blanc et s'appelait Marengo.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 16, 'total_tokens': 34, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_67802d9a6d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-c1aceffc-7229-4d5d-ad24-571f1e677114-0', usage_metadata={'input_tokens': 16, 'output_tokens': 18, 'total_tokens': 34})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Couleur du cheval de Napoléon ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_books(file_path):\n",
    "    # Charger les livres depuis un fichier CSV\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Créer une liste de documents à partir des colonnes du CSV\n",
    "        documents = [\n",
    "            Document(page_content=row['summary'], metadata={\"title\": row['title'], \"author\": row['author']})\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use a CSV file.\")\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_file_path = \"cleaned_books.csv\"\n",
    "documents = load_books(books_file_path)\n",
    "\n",
    "# Créer un index vectoriel avec InMemoryVectorStore\n",
    "index = InMemoryVectorStore.from_documents(\n",
    "    documents,\n",
    "    embedding=embedding_model  # Passer l'instance de l'embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent():\n",
    "    qa_prompt_template = PromptTemplate(\n",
    "        input_variables=[\"question\", \"documents\"],\n",
    "        template=\"\"\"Answer the question '{question}' based on the following documents: {documents}\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Créer la chaîne de question-réponse\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=model,  # Utiliser le modèle de langage ici\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=index.as_retriever()\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "def ask_question(question):\n",
    "    agent = create_agent()\n",
    "    response = agent.invoke(question)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse : {'query': 'Balzac a écrit quoi ?', 'result': 'Honoré de Balzac a écrit une vaste série de romans intitulée \"La Comédie Humaine,\" qui explore divers aspects de la société française du 19ème siècle. Parmi ses œuvres notables, on trouve \"Le Père Goriot,\" \"Eugénie Grandet,\" \"Illusions perdues,\" et \"Splendeurs et misères des courtisanes.\" Ses écrits abordent des thèmes tels que l\\'ambition, l\\'amour, la société, et l\\'économie.'}\n"
     ]
    }
   ],
   "source": [
    "question = \"Balzac a écrit quoi ?\"\n",
    "answer = ask_question(question)\n",
    "print(f\"Réponse : {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse : {'query': 'Couleur du soleil ?', 'result': 'Je suis désolé, je ne connais pas la réponse à votre question.'}\n"
     ]
    }
   ],
   "source": [
    "question = \"Couleur du soleil ?\"\n",
    "answer = ask_question(question)\n",
    "print(f\"Réponse : {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genailangchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
